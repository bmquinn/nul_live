# NUL Digital Collections API

```elixir
Mix.install(
  [
    {:nul, github: "bmquinn/nul_live"},
    {:vega_lite, "~> 0.1.6"},
    {:kino_vega_lite, "~> 0.1.7"},
    {:kino_bumblebee, "~> 0.1.4"},
    {:exla, "~> 0.4.1"}
  ],
  config: [nx: [default_backend: EXLA.Backend]]
)
```

## Smart Cell

<!-- livebook:{"attrs":{"format":"json","query_body":"{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match\": {\n           \"work_type\": \"Image\"\n        }\n      }\n    }\n  },\n  \"size\": 25\n}","variable":"result"},"chunks":null,"kind":"Elixir.Nul.SmartCell","livebook_object":"smart_cell"} -->

```elixir
result =
  Req.post!("https://api.dc.library.northwestern.edu/api/v2/search?as=json",
    body:
      "{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match\": {\n           \"work_type\": \"Image\"\n        }\n      }\n    }\n  },\n  \"size\": 25\n}"
  ).body
```

## Transforming the response

```elixir
dataset = Map.get(result, "data")

images =
  for {image, i} <- Enum.with_index(dataset, 1) do
    label =
      Kino.Markdown.new("""
         <div style="text-align: center">
          <p style="font-weight: bold;">#{i}/#{length(dataset)}</p>
          <p>#{image["title"]}</p>
         </div>
      """)

    link =
      Kino.Markdown.new(
        "[link](https://digitalcollections.library.northwestern.edu/items/#{image["id"]})"
      )

    image =
      Kino.Markdown.new(
        "![#{image["rights_statement"]["label"]}](#{image["thumbnail"] <> "?size=300"})"
      )

    Kino.Layout.grid([label, image, link], boxed: true)
  end

Kino.Layout.grid(images, columns: 2)
```

## Visualizations: graphs and tables

```elixir
dataset
|> Enum.map(fn record ->
  Map.take(record, ~w|id create_date description|)
end)
|> Kino.DataTable.new()
```

```elixir
alias VegaLite, as: Vl

Vl.new(width: 400, height: 400)
|> Vl.data_from_values(dataset)
|> Vl.mark(:bar)
|> Vl.encode_field(:x, "preservation_level")
|> Vl.encode(:y, aggregate: :count)
```

## Neural Networks models

```elixir
{:ok, model_info} = Bumblebee.load_model({:hf, "dslim/bert-base-NER"}, log_params_diff: false)

{:ok, tokenizer} = Bumblebee.load_tokenizer({:hf, "bert-base-cased"})

serving =
  Bumblebee.Text.token_classification(model_info, tokenizer,
    aggregation: :same,
    compile: [batch_size: 1, sequence_length: 100],
    defn_options: [compiler: EXLA]
  )

select_input =
  Kino.Input.select("Choose field:",
    multivalued_description: "Description",
    singular_title: "Title",
    multivalued_alternate_title: "Alternate Title"
  )

form = Kino.Control.form([selected: select_input], submit: "Run")
frame = Kino.Frame.new()

form
|> Kino.Control.stream()
|> Kino.listen(fn %{data: %{selected: selected}} ->
  selected = Atom.to_string(selected)

  texts =
    case selected do
      "singular_" <> field ->
        dataset
        |> Enum.map(&Map.get(&1, field))

      "multivalued_" <> field ->
        dataset
        |> Enum.flat_map(&Map.get(&1, field))
    end

  case texts do
    [] ->
      Kino.Frame.render(frame, Kino.Markdown.new("No values for that field"))

    _ ->
      Kino.Frame.render(frame, Kino.Markdown.new(""))

      Enum.each(texts, fn text ->
        output = Nx.Serving.run(serving, text)
        Kino.Frame.append(frame, Kino.Bumblebee.HighlightedText.new(text, output.entities))
      end)
  end
end)

Kino.Layout.grid([form, frame], boxed: true, gap: 16)
```
