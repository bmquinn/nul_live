# NUL Digital Collections API

```elixir
Mix.install(
  [
    {:nul, github: "bmquinn/nul_live"},
    {:vega_lite, "~> 0.1.6"},
    {:kino_vega_lite, "~> 0.1.7"},
    {:kino_bumblebee, "~> 0.1.0"},
    {:exla, "~> 0.4.1"}
  ],
  config: [nx: [default_backend: EXLA.Backend]]
)
```

## Smart Cell

<!-- livebook:{"attrs":{"format":"json","query_body":"{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match\": {\n           \"work_type\": \"Image\"\n        }\n      }\n    }\n  },\n  \"size\": 25\n}","variable":"result"},"chunks":null,"kind":"Elixir.Nul.SmartCell","livebook_object":"smart_cell"} -->

```elixir
result =
  Req.post!("https://dcapi.rdc.library.northwestern.edu/api/v2/search?as=json",
    body:
      "{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match\": {\n           \"work_type\": \"Image\"\n        }\n      }\n    }\n  },\n  \"size\": 25\n}"
  )
```

## Transforming the response

```elixir
data =
  result.body
  |> Map.get("data")

images =
  for {image, i} <- Enum.with_index(data, 1) do
    label =
      Kino.Markdown.new("""
         <div style="text-align: center">
          <p style="font-weight: bold;">#{i}/#{length(data)}</p>
          <p>#{image["title"]}</p>
         </div>
      """)

    link =
      Kino.Markdown.new(
        "[link](https://digitalcollections.library.northwestern.edu/items/#{image["id"]})"
      )

    image =
      Kino.Markdown.new(
        "![#{image["rights_statement"]["label"]}](#{image["thumbnail"] <> "?size=300"})"
      )

    Kino.Layout.grid([label, image, link], boxed: true)
  end

Kino.Layout.grid(images, columns: 2)
```

## Visualizations: graphs and tables

```elixir
alias VegaLite, as: Vl

data = Map.get(result.body, "data")

Vl.new()
|> Vl.data_from_values(data)
|> Vl.mark(:bar)
|> Vl.encode_field(:x, "preservation_level")
|> Vl.encode(:y, aggregate: :count)
```

```elixir
data
|> Enum.map(fn record ->
  Map.take(record, ~w|id create_date description|)
end)
|> Kino.DataTable.new()
```

## Neural Networks models

```elixir
frame = Kino.Frame.new()
```

```elixir
{:ok, model_info} = Bumblebee.load_model({:hf, "dslim/bert-base-NER"}, log_params_diff: false)

{:ok, tokenizer} = Bumblebee.load_tokenizer({:hf, "bert-base-cased"})

serving =
  Bumblebee.Text.token_classification(model_info, tokenizer,
    aggregation: :same,
    compile: [batch_size: 1, sequence_length: 100],
    defn_options: [compiler: EXLA]
  )

data
|> Enum.flat_map(&Map.get(&1, "description"))
|> Enum.each(fn text ->
  output = Nx.Serving.run(serving, text)
  Kino.Frame.append(frame, Kino.Bumblebee.HighlightedText.new(text, output.entities))
end)
```
